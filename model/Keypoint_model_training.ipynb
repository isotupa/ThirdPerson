{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "igMyGnjE9hEp"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2HDvhIu9hEr"
   },
   "source": [
    "# Specify each path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "9NvZP2Zn9hEy"
   },
   "outputs": [],
   "source": [
    "# Specify data paths\n",
    "dataset = 'model/keypoint_classifier/keypoint.csv'\n",
    "model_save_path = 'model/keypoint_classifier/keypoint_classifier.hdf5'\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5oMH7x19hEz"
   },
   "source": [
    "# Set number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "du4kodXL9hEz"
   },
   "outputs": [],
   "source": [
    "# Change training classes if necessary\n",
    "NUM_CLASSES = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjnL0uso9hEz"
   },
   "source": [
    "# Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "QT5ZqtEz9hE0"
   },
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "QmoKFsp49hE0"
   },
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "xQU7JTZ_9hE0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "xElG5FoPDQO9",
    "outputId": "2ef372ed-62e3-49c1-ad36-a5b5dc76701a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=int32), array([1595, 1663, 1510,  672,  164,  257,  139,  190,   75]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classes count\n",
    "counts = np.unique(y_dataset, return_counts=True)\n",
    "df = pd.DataFrame(counts)\n",
    "df.T.plot(kind=\"bar\", stacked=True)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxK_lETT9hE0"
   },
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "vHBmUf1t9hE1"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.0),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.0),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.0),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypqky9tc9hE1",
    "outputId": "c42f3550-ceee-45b8-d40d-d99fd84a2616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_6 (Dropout)         (None, 42)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                1376      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 9)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3113 (12.16 KB)\n",
      "Trainable params: 3113 (12.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "MbMjOflQ9hE1"
   },
   "outputs": [],
   "source": [
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False, save_best_only=True)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "c3Dac0M_9hE2"
   },
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XI0j1Iu9hE2"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "WirBl-JE9hE3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 1.9344 - accuracy: 0.3303\n",
      "Epoch 1: val_loss improved from inf to 1.43504, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 2s 6ms/step - loss: 1.8560 - accuracy: 0.3604 - val_loss: 1.4350 - val_accuracy: 0.5405\n",
      "Epoch 2/1000\n",
      "48/74 [==================>...........] - ETA: 0s - loss: 1.2397 - accuracy: 0.5859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 1.43504 to 0.91098, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 1.1636 - accuracy: 0.6117 - val_loss: 0.9110 - val_accuracy: 0.7071\n",
      "Epoch 3/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.8004 - accuracy: 0.7327\n",
      "Epoch 3: val_loss improved from 0.91098 to 0.61853, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.7588 - accuracy: 0.7554 - val_loss: 0.6185 - val_accuracy: 0.8066\n",
      "Epoch 4/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.5240 - accuracy: 0.8629\n",
      "Epoch 4: val_loss improved from 0.61853 to 0.43062, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.8708 - val_loss: 0.4306 - val_accuracy: 0.9075\n",
      "Epoch 5/1000\n",
      "62/74 [========================>.....] - ETA: 0s - loss: 0.3686 - accuracy: 0.9173\n",
      "Epoch 5: val_loss improved from 0.43062 to 0.32130, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.9221 - val_loss: 0.3213 - val_accuracy: 0.9311\n",
      "Epoch 6/1000\n",
      "61/74 [=======================>......] - ETA: 0s - loss: 0.2760 - accuracy: 0.9439\n",
      "Epoch 6: val_loss improved from 0.32130 to 0.26164, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.9434 - val_loss: 0.2616 - val_accuracy: 0.9483\n",
      "Epoch 7/1000\n",
      "52/74 [====================>.........] - ETA: 0s - loss: 0.2277 - accuracy: 0.9549\n",
      "Epoch 7: val_loss improved from 0.26164 to 0.21268, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.9579 - val_loss: 0.2127 - val_accuracy: 0.9541\n",
      "Epoch 8/1000\n",
      "52/74 [====================>.........] - ETA: 0s - loss: 0.1857 - accuracy: 0.9621\n",
      "Epoch 8: val_loss improved from 0.21268 to 0.17831, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.1742 - accuracy: 0.9645 - val_loss: 0.1783 - val_accuracy: 0.9604\n",
      "Epoch 9/1000\n",
      "59/74 [======================>.......] - ETA: 0s - loss: 0.1470 - accuracy: 0.9680\n",
      "Epoch 9: val_loss improved from 0.17831 to 0.15201, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9683 - val_loss: 0.1520 - val_accuracy: 0.9675\n",
      "Epoch 10/1000\n",
      "60/74 [=======================>......] - ETA: 0s - loss: 0.1225 - accuracy: 0.9740\n",
      "Epoch 10: val_loss improved from 0.15201 to 0.12421, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9740 - val_loss: 0.1242 - val_accuracy: 0.9777\n",
      "Epoch 11/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.1002 - accuracy: 0.9781\n",
      "Epoch 11: val_loss improved from 0.12421 to 0.10865, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9785 - val_loss: 0.1087 - val_accuracy: 0.9821\n",
      "Epoch 12/1000\n",
      "60/74 [=======================>......] - ETA: 0s - loss: 0.0862 - accuracy: 0.9826\n",
      "Epoch 12: val_loss improved from 0.10865 to 0.09852, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9838 - val_loss: 0.0985 - val_accuracy: 0.9840\n",
      "Epoch 13/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0756 - accuracy: 0.9860\n",
      "Epoch 13: val_loss improved from 0.09852 to 0.09118, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9853 - val_loss: 0.0912 - val_accuracy: 0.9828\n",
      "Epoch 14/1000\n",
      "62/74 [========================>.....] - ETA: 0s - loss: 0.0725 - accuracy: 0.9859\n",
      "Epoch 14: val_loss improved from 0.09118 to 0.08208, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9855 - val_loss: 0.0821 - val_accuracy: 0.9860\n",
      "Epoch 15/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 0.0593 - accuracy: 0.9876\n",
      "Epoch 15: val_loss improved from 0.08208 to 0.08031, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9866 - val_loss: 0.0803 - val_accuracy: 0.9834\n",
      "Epoch 16/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0576 - accuracy: 0.9879\n",
      "Epoch 16: val_loss improved from 0.08031 to 0.06194, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9881 - val_loss: 0.0619 - val_accuracy: 0.9879\n",
      "Epoch 17/1000\n",
      "63/74 [========================>.....] - ETA: 0s - loss: 0.0553 - accuracy: 0.9871\n",
      "Epoch 17: val_loss improved from 0.06194 to 0.06024, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9881 - val_loss: 0.0602 - val_accuracy: 0.9872\n",
      "Epoch 18/1000\n",
      "60/74 [=======================>......] - ETA: 0s - loss: 0.0492 - accuracy: 0.9896\n",
      "Epoch 18: val_loss improved from 0.06024 to 0.05973, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9904 - val_loss: 0.0597 - val_accuracy: 0.9866\n",
      "Epoch 19/1000\n",
      "62/74 [========================>.....] - ETA: 0s - loss: 0.0412 - accuracy: 0.9919\n",
      "Epoch 19: val_loss improved from 0.05973 to 0.05336, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9908 - val_loss: 0.0534 - val_accuracy: 0.9879\n",
      "Epoch 20/1000\n",
      "61/74 [=======================>......] - ETA: 0s - loss: 0.0419 - accuracy: 0.9903\n",
      "Epoch 20: val_loss improved from 0.05336 to 0.05189, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9904 - val_loss: 0.0519 - val_accuracy: 0.9885\n",
      "Epoch 21/1000\n",
      "62/74 [========================>.....] - ETA: 0s - loss: 0.0420 - accuracy: 0.9899\n",
      "Epoch 21: val_loss improved from 0.05189 to 0.04589, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9906 - val_loss: 0.0459 - val_accuracy: 0.9892\n",
      "Epoch 22/1000\n",
      "60/74 [=======================>......] - ETA: 0s - loss: 0.0380 - accuracy: 0.9901\n",
      "Epoch 22: val_loss did not improve from 0.04589\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9904 - val_loss: 0.0481 - val_accuracy: 0.9892\n",
      "Epoch 23/1000\n",
      "62/74 [========================>.....] - ETA: 0s - loss: 0.0340 - accuracy: 0.9914\n",
      "Epoch 23: val_loss improved from 0.04589 to 0.04153, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9913 - val_loss: 0.0415 - val_accuracy: 0.9923\n",
      "Epoch 24/1000\n",
      "61/74 [=======================>......] - ETA: 0s - loss: 0.0316 - accuracy: 0.9939\n",
      "Epoch 24: val_loss improved from 0.04153 to 0.04124, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9943 - val_loss: 0.0412 - val_accuracy: 0.9904\n",
      "Epoch 25/1000\n",
      "59/74 [======================>.......] - ETA: 0s - loss: 0.0288 - accuracy: 0.9936\n",
      "Epoch 25: val_loss did not improve from 0.04124\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.9934 - val_loss: 0.0426 - val_accuracy: 0.9898\n",
      "Epoch 26/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0273 - accuracy: 0.9941\n",
      "Epoch 26: val_loss improved from 0.04124 to 0.03969, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9943 - val_loss: 0.0397 - val_accuracy: 0.9936\n",
      "Epoch 27/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 0.0269 - accuracy: 0.9931\n",
      "Epoch 27: val_loss improved from 0.03969 to 0.03752, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9932 - val_loss: 0.0375 - val_accuracy: 0.9943\n",
      "Epoch 28/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0246 - accuracy: 0.9947\n",
      "Epoch 28: val_loss did not improve from 0.03752\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9940 - val_loss: 0.0446 - val_accuracy: 0.9911\n",
      "Epoch 29/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0234 - accuracy: 0.9943\n",
      "Epoch 29: val_loss improved from 0.03752 to 0.03242, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.9951 - val_loss: 0.0324 - val_accuracy: 0.9936\n",
      "Epoch 30/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0229 - accuracy: 0.9949\n",
      "Epoch 30: val_loss did not improve from 0.03242\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9947 - val_loss: 0.0340 - val_accuracy: 0.9943\n",
      "Epoch 31/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 0.0216 - accuracy: 0.9954\n",
      "Epoch 31: val_loss improved from 0.03242 to 0.03155, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9955 - val_loss: 0.0315 - val_accuracy: 0.9923\n",
      "Epoch 32/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0185 - accuracy: 0.9962\n",
      "Epoch 32: val_loss did not improve from 0.03155\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.0352 - val_accuracy: 0.9923\n",
      "Epoch 33/1000\n",
      "62/74 [========================>.....] - ETA: 0s - loss: 0.0226 - accuracy: 0.9952\n",
      "Epoch 33: val_loss did not improve from 0.03155\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9953 - val_loss: 0.0352 - val_accuracy: 0.9904\n",
      "Epoch 34/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0165 - accuracy: 0.9964\n",
      "Epoch 34: val_loss improved from 0.03155 to 0.02832, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.0283 - val_accuracy: 0.9943\n",
      "Epoch 35/1000\n",
      "50/74 [===================>..........] - ETA: 0s - loss: 0.0185 - accuracy: 0.9966\n",
      "Epoch 35: val_loss improved from 0.02832 to 0.02602, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9968 - val_loss: 0.0260 - val_accuracy: 0.9949\n",
      "Epoch 36/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0154 - accuracy: 0.9973\n",
      "Epoch 36: val_loss did not improve from 0.02602\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9966 - val_loss: 0.0325 - val_accuracy: 0.9936\n",
      "Epoch 37/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 0.0145 - accuracy: 0.9980\n",
      "Epoch 37: val_loss did not improve from 0.02602\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9972 - val_loss: 0.0308 - val_accuracy: 0.9949\n",
      "Epoch 38/1000\n",
      "51/74 [===================>..........] - ETA: 0s - loss: 0.0148 - accuracy: 0.9963\n",
      "Epoch 38: val_loss did not improve from 0.02602\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9964 - val_loss: 0.0279 - val_accuracy: 0.9943\n",
      "Epoch 39/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0138 - accuracy: 0.9964\n",
      "Epoch 39: val_loss did not improve from 0.02602\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 0.0286 - val_accuracy: 0.9949\n",
      "Epoch 40/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0134 - accuracy: 0.9974\n",
      "Epoch 40: val_loss improved from 0.02602 to 0.02551, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.0255 - val_accuracy: 0.9936\n",
      "Epoch 41/1000\n",
      "56/74 [=====================>........] - ETA: 0s - loss: 0.0139 - accuracy: 0.9961\n",
      "Epoch 41: val_loss improved from 0.02551 to 0.02375, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0237 - val_accuracy: 0.9955\n",
      "Epoch 42/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0134 - accuracy: 0.9973\n",
      "Epoch 42: val_loss did not improve from 0.02375\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.0281 - val_accuracy: 0.9936\n",
      "Epoch 43/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 0.0120 - accuracy: 0.9970\n",
      "Epoch 43: val_loss did not improve from 0.02375\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.0271 - val_accuracy: 0.9917\n",
      "Epoch 44/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0101 - accuracy: 0.9979\n",
      "Epoch 44: val_loss did not improve from 0.02375\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.0310 - val_accuracy: 0.9917\n",
      "Epoch 45/1000\n",
      "60/74 [=======================>......] - ETA: 0s - loss: 0.0086 - accuracy: 0.9987\n",
      "Epoch 45: val_loss did not improve from 0.02375\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 0.0300 - val_accuracy: 0.9943\n",
      "Epoch 46/1000\n",
      "59/74 [======================>.......] - ETA: 0s - loss: 0.0091 - accuracy: 0.9981\n",
      "Epoch 46: val_loss improved from 0.02375 to 0.02264, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0226 - val_accuracy: 0.9955\n",
      "Epoch 47/1000\n",
      "70/74 [===========================>..] - ETA: 0s - loss: 0.0108 - accuracy: 0.9975\n",
      "Epoch 47: val_loss did not improve from 0.02264\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0263 - val_accuracy: 0.9930\n",
      "Epoch 48/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0088 - accuracy: 0.9976\n",
      "Epoch 48: val_loss did not improve from 0.02264\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.0387 - val_accuracy: 0.9898\n",
      "Epoch 49/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0150 - accuracy: 0.9956\n",
      "Epoch 49: val_loss did not improve from 0.02264\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.0246 - val_accuracy: 0.9943\n",
      "Epoch 50/1000\n",
      "66/74 [=========================>....] - ETA: 0s - loss: 0.0096 - accuracy: 0.9972\n",
      "Epoch 50: val_loss improved from 0.02264 to 0.02158, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.0216 - val_accuracy: 0.9962\n",
      "Epoch 51/1000\n",
      "72/74 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9978\n",
      "Epoch 51: val_loss did not improve from 0.02158\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.0275 - val_accuracy: 0.9930\n",
      "Epoch 52/1000\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9972\n",
      "Epoch 52: val_loss did not improve from 0.02158\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0228 - val_accuracy: 0.9949\n",
      "Epoch 53/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0081 - accuracy: 0.9985\n",
      "Epoch 53: val_loss did not improve from 0.02158\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0241 - val_accuracy: 0.9943\n",
      "Epoch 54/1000\n",
      "68/74 [==========================>...] - ETA: 0s - loss: 0.0082 - accuracy: 0.9982\n",
      "Epoch 54: val_loss did not improve from 0.02158\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.0229 - val_accuracy: 0.9949\n",
      "Epoch 55/1000\n",
      "52/74 [====================>.........] - ETA: 0s - loss: 0.0068 - accuracy: 0.9985\n",
      "Epoch 55: val_loss did not improve from 0.02158\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0226 - val_accuracy: 0.9943\n",
      "Epoch 56/1000\n",
      "62/74 [========================>.....] - ETA: 0s - loss: 0.0088 - accuracy: 0.9980\n",
      "Epoch 56: val_loss did not improve from 0.02158\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0362 - val_accuracy: 0.9917\n",
      "Epoch 57/1000\n",
      "56/74 [=====================>........] - ETA: 0s - loss: 0.0107 - accuracy: 0.9978\n",
      "Epoch 57: val_loss did not improve from 0.02158\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 0.0303 - val_accuracy: 0.9936\n",
      "Epoch 58/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0075 - accuracy: 0.9980\n",
      "Epoch 58: val_loss did not improve from 0.02158\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.0228 - val_accuracy: 0.9949\n",
      "Epoch 59/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 0.0095 - accuracy: 0.9980\n",
      "Epoch 59: val_loss did not improve from 0.02158\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0234 - val_accuracy: 0.9943\n",
      "Epoch 60/1000\n",
      "60/74 [=======================>......] - ETA: 0s - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 60: val_loss did not improve from 0.02158\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0271 - val_accuracy: 0.9936\n",
      "Epoch 61/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 0.0080 - accuracy: 0.9983\n",
      "Epoch 61: val_loss improved from 0.02158 to 0.01849, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.0185 - val_accuracy: 0.9949\n",
      "Epoch 62/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0077 - accuracy: 0.9978\n",
      "Epoch 62: val_loss did not improve from 0.01849\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0189 - val_accuracy: 0.9955\n",
      "Epoch 63/1000\n",
      "56/74 [=====================>........] - ETA: 0s - loss: 0.0054 - accuracy: 0.9989\n",
      "Epoch 63: val_loss did not improve from 0.01849\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.0237 - val_accuracy: 0.9930\n",
      "Epoch 64/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0065 - accuracy: 0.9978\n",
      "Epoch 64: val_loss did not improve from 0.01849\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0237 - val_accuracy: 0.9943\n",
      "Epoch 65/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0055 - accuracy: 0.9991\n",
      "Epoch 65: val_loss did not improve from 0.01849\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0248 - val_accuracy: 0.9936\n",
      "Epoch 66/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 66: val_loss did not improve from 0.01849\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0224 - val_accuracy: 0.9943\n",
      "Epoch 67/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0071 - accuracy: 0.9981\n",
      "Epoch 67: val_loss did not improve from 0.01849\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0236 - val_accuracy: 0.9923\n",
      "Epoch 68/1000\n",
      "67/74 [==========================>...] - ETA: 0s - loss: 0.0067 - accuracy: 0.9979\n",
      "Epoch 68: val_loss did not improve from 0.01849\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0286 - val_accuracy: 0.9923\n",
      "Epoch 69/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0056 - accuracy: 0.9984\n",
      "Epoch 69: val_loss improved from 0.01849 to 0.01731, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0173 - val_accuracy: 0.9949\n",
      "Epoch 70/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0051 - accuracy: 0.9989\n",
      "Epoch 70: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0192 - val_accuracy: 0.9949\n",
      "Epoch 71/1000\n",
      "50/74 [===================>..........] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 71: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0260 - val_accuracy: 0.9923\n",
      "Epoch 72/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 72: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0201 - val_accuracy: 0.9949\n",
      "Epoch 73/1000\n",
      "56/74 [=====================>........] - ETA: 0s - loss: 0.0076 - accuracy: 0.9975  \n",
      "Epoch 73: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0268 - val_accuracy: 0.9936\n",
      "Epoch 74/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 0.0064 - accuracy: 0.9978\n",
      "Epoch 74: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0282 - val_accuracy: 0.9930\n",
      "Epoch 75/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0068 - accuracy: 0.9975  \n",
      "Epoch 75: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0210 - val_accuracy: 0.9936\n",
      "Epoch 76/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988  \n",
      "Epoch 76: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0221 - val_accuracy: 0.9949\n",
      "Epoch 77/1000\n",
      "59/74 [======================>.......] - ETA: 0s - loss: 0.0112 - accuracy: 0.9974\n",
      "Epoch 77: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 0.0238 - val_accuracy: 0.9949\n",
      "Epoch 78/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 0.0079 - accuracy: 0.9974\n",
      "Epoch 78: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0226 - val_accuracy: 0.9930\n",
      "Epoch 79/1000\n",
      "59/74 [======================>.......] - ETA: 0s - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 79: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0208 - val_accuracy: 0.9949\n",
      "Epoch 80/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0118 - accuracy: 0.9975\n",
      "Epoch 80: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 0.0243 - val_accuracy: 0.9936\n",
      "Epoch 81/1000\n",
      "56/74 [=====================>........] - ETA: 0s - loss: 0.0027 - accuracy: 0.9994  \n",
      "Epoch 81: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0194 - val_accuracy: 0.9943\n",
      "Epoch 82/1000\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 0.0025 - accuracy: 0.9996\n",
      "Epoch 82: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0177 - val_accuracy: 0.9955\n",
      "Epoch 83/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995\n",
      "Epoch 83: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0195 - val_accuracy: 0.9949\n",
      "Epoch 84/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0024 - accuracy: 0.9994  \n",
      "Epoch 84: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0208 - val_accuracy: 0.9936\n",
      "Epoch 85/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 0.0024 - accuracy: 0.9997  \n",
      "Epoch 85: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0274 - val_accuracy: 0.9923\n",
      "Epoch 86/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 86: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0215 - val_accuracy: 0.9949\n",
      "Epoch 87/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 87: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0206 - val_accuracy: 0.9949\n",
      "Epoch 88/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0038 - accuracy: 0.9986  \n",
      "Epoch 88: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9981 - val_loss: 0.0184 - val_accuracy: 0.9923\n",
      "Epoch 89/1000\n",
      "59/74 [======================>.......] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 89: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0381 - val_accuracy: 0.9917\n",
      "Epoch 90/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 0.0089 - accuracy: 0.9987\n",
      "Epoch 90: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.0240 - val_accuracy: 0.9936\n",
      "Epoch 91/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 0.0026 - accuracy: 0.9997\n",
      "Epoch 91: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0217 - val_accuracy: 0.9955\n",
      "Epoch 92/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000  \n",
      "Epoch 92: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0222 - val_accuracy: 0.9943\n",
      "Epoch 93/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 0.0029 - accuracy: 0.9988\n",
      "Epoch 93: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0212 - val_accuracy: 0.9943\n",
      "Epoch 94/1000\n",
      "52/74 [====================>.........] - ETA: 0s - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 94: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0178 - val_accuracy: 0.9949\n",
      "Epoch 95/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0054 - accuracy: 0.9979  \n",
      "Epoch 95: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.0273 - val_accuracy: 0.9923\n",
      "Epoch 96/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0077 - accuracy: 0.9971  \n",
      "Epoch 96: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0241 - val_accuracy: 0.9943\n",
      "Epoch 97/1000\n",
      "62/74 [========================>.....] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 97: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0277 - val_accuracy: 0.9917\n",
      "Epoch 98/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0026 - accuracy: 0.9994  \n",
      "Epoch 98: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0190 - val_accuracy: 0.9943\n",
      "Epoch 99/1000\n",
      "56/74 [=====================>........] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 99: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0223 - val_accuracy: 0.9949\n",
      "Epoch 100/1000\n",
      "56/74 [=====================>........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 100: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9943\n",
      "Epoch 101/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 101: val_loss did not improve from 0.01731\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0268 - val_accuracy: 0.9936\n",
      "Epoch 102/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989  \n",
      "Epoch 102: val_loss improved from 0.01731 to 0.01662, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0166 - val_accuracy: 0.9949\n",
      "Epoch 103/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994  \n",
      "Epoch 103: val_loss did not improve from 0.01662\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0313 - val_accuracy: 0.9917\n",
      "Epoch 104/1000\n",
      "49/74 [==================>...........] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994  \n",
      "Epoch 104: val_loss did not improve from 0.01662\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0205 - val_accuracy: 0.9949\n",
      "Epoch 105/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 105: val_loss did not improve from 0.01662\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0218 - val_accuracy: 0.9943\n",
      "Epoch 106/1000\n",
      "56/74 [=====================>........] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997  \n",
      "Epoch 106: val_loss did not improve from 0.01662\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0175 - val_accuracy: 0.9955\n",
      "Epoch 107/1000\n",
      "56/74 [=====================>........] - ETA: 0s - loss: 0.0087 - accuracy: 0.9964\n",
      "Epoch 107: val_loss improved from 0.01662 to 0.01569, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.0157 - val_accuracy: 0.9962\n",
      "Epoch 108/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0026 - accuracy: 0.9989\n",
      "Epoch 108: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.0201 - val_accuracy: 0.9949\n",
      "Epoch 109/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 8.5507e-04 - accuracy: 1.0000\n",
      "Epoch 109: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9949\n",
      "Epoch 110/1000\n",
      "47/74 [==================>...........] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997  \n",
      "Epoch 110: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0179 - val_accuracy: 0.9955\n",
      "Epoch 111/1000\n",
      "51/74 [===================>..........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 111: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9943\n",
      "Epoch 112/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989  \n",
      "Epoch 112: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0169 - val_accuracy: 0.9955\n",
      "Epoch 113/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 7.8735e-04 - accuracy: 1.0000\n",
      "Epoch 113: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0250 - val_accuracy: 0.9923\n",
      "Epoch 114/1000\n",
      "59/74 [======================>.......] - ETA: 0s - loss: 0.0067 - accuracy: 0.9976\n",
      "Epoch 114: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.0257 - val_accuracy: 0.9936\n",
      "Epoch 115/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 0.0064 - accuracy: 0.9977  \n",
      "Epoch 115: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0231 - val_accuracy: 0.9923\n",
      "Epoch 116/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0026 - accuracy: 0.9994  \n",
      "Epoch 116: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0230 - val_accuracy: 0.9930\n",
      "Epoch 117/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 117: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 9.7028e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9949\n",
      "Epoch 118/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 7.3082e-04 - accuracy: 1.0000\n",
      "Epoch 118: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 8.1197e-04 - accuracy: 0.9998 - val_loss: 0.0180 - val_accuracy: 0.9955\n",
      "Epoch 119/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 0.0035 - accuracy: 0.9983  \n",
      "Epoch 119: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.0221 - val_accuracy: 0.9943\n",
      "Epoch 120/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000  \n",
      "Epoch 120: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9949\n",
      "Epoch 121/1000\n",
      "56/74 [=====================>........] - ETA: 0s - loss: 5.3806e-04 - accuracy: 1.0000\n",
      "Epoch 121: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0229 - val_accuracy: 0.9949\n",
      "Epoch 122/1000\n",
      "72/74 [============================>.] - ETA: 0s - loss: 9.8940e-04 - accuracy: 1.0000\n",
      "Epoch 122: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 9.7409e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9955\n",
      "Epoch 123/1000\n",
      "59/74 [======================>.......] - ETA: 0s - loss: 6.5453e-04 - accuracy: 1.0000\n",
      "Epoch 123: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 8.9428e-04 - accuracy: 0.9998 - val_loss: 0.0184 - val_accuracy: 0.9943\n",
      "Epoch 124/1000\n",
      "56/74 [=====================>........] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 124: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0185 - val_accuracy: 0.9949\n",
      "Epoch 125/1000\n",
      "51/74 [===================>..........] - ETA: 0s - loss: 0.0017 - accuracy: 0.9991  \n",
      "Epoch 125: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 0.0195 - val_accuracy: 0.9955\n",
      "Epoch 126/1000\n",
      "54/74 [====================>.........] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988    \n",
      "Epoch 126: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0276 - val_accuracy: 0.9943\n",
      "Epoch 127/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0068 - accuracy: 0.9984  \n",
      "Epoch 127: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0191 - val_accuracy: 0.9949\n",
      "Epoch 128/1000\n",
      "51/74 [===================>..........] - ETA: 0s - loss: 9.8302e-04 - accuracy: 1.0000\n",
      "Epoch 128: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 9.8330e-04 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9955\n",
      "Epoch 129/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997  \n",
      "Epoch 129: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 9.8856e-04 - accuracy: 0.9998 - val_loss: 0.0186 - val_accuracy: 0.9955\n",
      "Epoch 130/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 7.9104e-04 - accuracy: 1.0000\n",
      "Epoch 130: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0197 - val_accuracy: 0.9949\n",
      "Epoch 131/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 5.9627e-04 - accuracy: 1.0000\n",
      "Epoch 131: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 8.3140e-04 - accuracy: 0.9998 - val_loss: 0.0198 - val_accuracy: 0.9949\n",
      "Epoch 132/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 7.2595e-04 - accuracy: 0.9997\n",
      "Epoch 132: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0188 - val_accuracy: 0.9955\n",
      "Epoch 133/1000\n",
      "72/74 [============================>.] - ETA: 0s - loss: 4.7783e-04 - accuracy: 1.0000\n",
      "Epoch 133: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 5.1674e-04 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9955\n",
      "Epoch 134/1000\n",
      "66/74 [=========================>....] - ETA: 0s - loss: 3.8388e-04 - accuracy: 1.0000\n",
      "Epoch 134: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 4.1109e-04 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9955\n",
      "Epoch 135/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 2.8247e-04 - accuracy: 1.0000\n",
      "Epoch 135: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 3.2949e-04 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9955\n",
      "Epoch 136/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 3.5657e-04 - accuracy: 1.0000\n",
      "Epoch 136: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 3.9941e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9955\n",
      "Epoch 137/1000\n",
      "74/74 [==============================] - ETA: 0s - loss: 4.1668e-04 - accuracy: 1.0000\n",
      "Epoch 137: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 4.1668e-04 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9955\n",
      "Epoch 138/1000\n",
      "51/74 [===================>..........] - ETA: 0s - loss: 2.0729e-04 - accuracy: 1.0000\n",
      "Epoch 138: val_loss did not improve from 0.01569\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 3.6269e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9955\n",
      "Epoch 139/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 0.0013 - accuracy: 0.9994    \n",
      "Epoch 139: val_loss improved from 0.01569 to 0.01473, saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.0147 - val_accuracy: 0.9955\n",
      "Epoch 140/1000\n",
      "73/74 [============================>.] - ETA: 0s - loss: 5.0120e-04 - accuracy: 1.0000\n",
      "Epoch 140: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 4.9860e-04 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9955\n",
      "Epoch 141/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 3.0330e-04 - accuracy: 1.0000\n",
      "Epoch 141: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 4.4145e-04 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9955\n",
      "Epoch 142/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 4.1960e-04 - accuracy: 1.0000\n",
      "Epoch 142: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 6.4330e-04 - accuracy: 0.9998 - val_loss: 0.0215 - val_accuracy: 0.9949\n",
      "Epoch 143/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 4.8989e-04 - accuracy: 1.0000\n",
      "Epoch 143: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0189 - val_accuracy: 0.9955\n",
      "Epoch 144/1000\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 0.0053 - accuracy: 0.9989\n",
      "Epoch 144: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0164 - val_accuracy: 0.9949\n",
      "Epoch 145/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0068 - accuracy: 0.9970  \n",
      "Epoch 145: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9968 - val_loss: 0.1454 - val_accuracy: 0.9649\n",
      "Epoch 146/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 0.0186 - accuracy: 0.9949\n",
      "Epoch 146: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9951 - val_loss: 0.0323 - val_accuracy: 0.9936\n",
      "Epoch 147/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0038 - accuracy: 0.9986  \n",
      "Epoch 147: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0298 - val_accuracy: 0.9943\n",
      "Epoch 148/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 8.3721e-04 - accuracy: 1.0000\n",
      "Epoch 148: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 8.2105e-04 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9949\n",
      "Epoch 149/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 4.9245e-04 - accuracy: 1.0000\n",
      "Epoch 149: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 4.9372e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9949\n",
      "Epoch 150/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 3.4584e-04 - accuracy: 1.0000\n",
      "Epoch 150: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 3.5198e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9949\n",
      "Epoch 151/1000\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 3.0266e-04 - accuracy: 1.0000\n",
      "Epoch 151: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 3.1362e-04 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9949\n",
      "Epoch 152/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 2.6017e-04 - accuracy: 1.0000\n",
      "Epoch 152: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 2.9110e-04 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9949\n",
      "Epoch 153/1000\n",
      "56/74 [=====================>........] - ETA: 0s - loss: 2.8792e-04 - accuracy: 1.0000\n",
      "Epoch 153: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 2.8704e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9949\n",
      "Epoch 154/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 3.2859e-04 - accuracy: 1.0000\n",
      "Epoch 154: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 3.0892e-04 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9943\n",
      "Epoch 155/1000\n",
      "52/74 [====================>.........] - ETA: 0s - loss: 2.0405e-04 - accuracy: 1.0000\n",
      "Epoch 155: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 2.6981e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9949\n",
      "Epoch 156/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 2.8030e-04 - accuracy: 1.0000\n",
      "Epoch 156: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 2.7634e-04 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9949\n",
      "Epoch 157/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 2.6031e-04 - accuracy: 1.0000\n",
      "Epoch 157: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 2.4672e-04 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9949\n",
      "Epoch 158/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 2.5009e-04 - accuracy: 1.0000\n",
      "Epoch 158: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 2.4060e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9949\n",
      "Epoch 159/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 3.1802e-04 - accuracy: 1.0000\n",
      "Epoch 159: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 2.8884e-04 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9949\n",
      "Epoch 160/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 2.3621e-04 - accuracy: 1.0000\n",
      "Epoch 160: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 2.9169e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9949\n",
      "Epoch 161/1000\n",
      "45/74 [=================>............] - ETA: 0s - loss: 3.1681e-04 - accuracy: 1.0000\n",
      "Epoch 161: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 5.3632e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9949\n",
      "Epoch 162/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 2.1609e-04 - accuracy: 1.0000\n",
      "Epoch 162: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 4.6919e-04 - accuracy: 0.9998 - val_loss: 0.0305 - val_accuracy: 0.9923\n",
      "Epoch 163/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 0.0034 - accuracy: 0.9987  \n",
      "Epoch 163: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0242 - val_accuracy: 0.9955\n",
      "Epoch 164/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995  \n",
      "Epoch 164: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0315 - val_accuracy: 0.9943\n",
      "Epoch 165/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 0.0023 - accuracy: 0.9995  \n",
      "Epoch 165: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0176 - val_accuracy: 0.9943\n",
      "Epoch 166/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0098 - accuracy: 0.9964  \n",
      "Epoch 166: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.0358 - val_accuracy: 0.9930\n",
      "Epoch 167/1000\n",
      "60/74 [=======================>......] - ETA: 0s - loss: 0.0048 - accuracy: 0.9977\n",
      "Epoch 167: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.9977 - val_loss: 0.0353 - val_accuracy: 0.9923\n",
      "Epoch 168/1000\n",
      "60/74 [=======================>......] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 168: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0291 - val_accuracy: 0.9917\n",
      "Epoch 169/1000\n",
      "60/74 [=======================>......] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995    \n",
      "Epoch 169: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0383 - val_accuracy: 0.9866\n",
      "Epoch 170/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992  \n",
      "Epoch 170: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.0240 - val_accuracy: 0.9949\n",
      "Epoch 171/1000\n",
      "72/74 [============================>.] - ETA: 0s - loss: 6.9549e-04 - accuracy: 1.0000\n",
      "Epoch 171: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 6.8324e-04 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9949\n",
      "Epoch 172/1000\n",
      "59/74 [======================>.......] - ETA: 0s - loss: 2.7854e-04 - accuracy: 1.0000\n",
      "Epoch 172: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.4181e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9949\n",
      "Epoch 173/1000\n",
      "52/74 [====================>.........] - ETA: 0s - loss: 2.4156e-04 - accuracy: 1.0000\n",
      "Epoch 173: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 2.6783e-04 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9949\n",
      "Epoch 174/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 8.1658e-04 - accuracy: 0.9997\n",
      "Epoch 174: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 6.6292e-04 - accuracy: 0.9998 - val_loss: 0.0189 - val_accuracy: 0.9955\n",
      "Epoch 175/1000\n",
      "57/74 [======================>.......] - ETA: 0s - loss: 0.0050 - accuracy: 0.9986  \n",
      "Epoch 175: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0292 - val_accuracy: 0.9949\n",
      "Epoch 176/1000\n",
      "59/74 [======================>.......] - ETA: 0s - loss: 0.0013 - accuracy: 0.9992  \n",
      "Epoch 176: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.0211 - val_accuracy: 0.9949\n",
      "Epoch 177/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 3.0470e-04 - accuracy: 1.0000\n",
      "Epoch 177: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 3.7217e-04 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9949\n",
      "Epoch 178/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 2.1280e-04 - accuracy: 1.0000\n",
      "Epoch 178: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 2.0756e-04 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9949\n",
      "Epoch 179/1000\n",
      "56/74 [=====================>........] - ETA: 0s - loss: 1.8280e-04 - accuracy: 1.0000\n",
      "Epoch 179: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 2.6886e-04 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 0.9949\n",
      "Epoch 180/1000\n",
      "71/74 [===========================>..] - ETA: 0s - loss: 2.3871e-04 - accuracy: 1.0000\n",
      "Epoch 180: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 2.3360e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9949\n",
      "Epoch 181/1000\n",
      "59/74 [======================>.......] - ETA: 0s - loss: 1.3913e-04 - accuracy: 1.0000\n",
      "Epoch 181: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 1.4876e-04 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 0.9955\n",
      "Epoch 182/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 1.4438e-04 - accuracy: 1.0000\n",
      "Epoch 182: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 1.3770e-04 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9955\n",
      "Epoch 183/1000\n",
      "55/74 [=====================>........] - ETA: 0s - loss: 1.5399e-04 - accuracy: 1.0000\n",
      "Epoch 183: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 1.4316e-04 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9949\n",
      "Epoch 184/1000\n",
      "62/74 [========================>.....] - ETA: 0s - loss: 1.3381e-04 - accuracy: 1.0000\n",
      "Epoch 184: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.3112e-04 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9955\n",
      "Epoch 185/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 1.1490e-04 - accuracy: 1.0000\n",
      "Epoch 185: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 1.3528e-04 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9955\n",
      "Epoch 186/1000\n",
      "58/74 [======================>.......] - ETA: 0s - loss: 1.3015e-04 - accuracy: 1.0000\n",
      "Epoch 186: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 1.4427e-04 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9955\n",
      "Epoch 187/1000\n",
      "53/74 [====================>.........] - ETA: 0s - loss: 1.7243e-04 - accuracy: 1.0000\n",
      "Epoch 187: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 1.5162e-04 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9955\n",
      "Epoch 188/1000\n",
      "69/74 [==========================>...] - ETA: 0s - loss: 1.4813e-04 - accuracy: 1.0000\n",
      "Epoch 188: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 1.4525e-04 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9955\n",
      "Epoch 189/1000\n",
      "59/74 [======================>.......] - ETA: 0s - loss: 1.1922e-04 - accuracy: 1.0000\n",
      "Epoch 189: val_loss did not improve from 0.01473\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 1.2330e-04 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9955\n",
      "Epoch 189: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x141136250>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "RBkmDeUW9hE4"
   },
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxvb2Y299hE3",
    "outputId": "7015e279-0501-4f24-d1b5-90652d2de17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9955\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "# TODO Test on loaded model\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFz9Tb0I9hE4",
    "outputId": "bb8a62a9-bf7d-4d99-8099-bda4e2e1c73a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n",
      "[2.4816995e-07 2.0154066e-04 2.8883248e-15 3.2730616e-16 2.9036948e-13\n",
      " 2.1070568e-07 8.5227388e-24 9.9979800e-01 1.8310771e-15]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Inference test\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3U4yNWx9hE4"
   },
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "AP1V6SCk9hE5",
    "outputId": "efce96b9-ca1c-44a5-ef77-58f1d5fc154c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       431\n",
      "           1       1.00      1.00      1.00       410\n",
      "           2       0.99      0.99      0.99       365\n",
      "           3       0.99      1.00      1.00       166\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.99      1.00      0.99        67\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           1.00      1567\n",
      "   macro avg       1.00      1.00      1.00      1567\n",
      "weighted avg       1.00      1.00      1.00      1567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNP6aqzc9hE5"
   },
   "source": [
    "# Convert to model for Tensorflow-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ODjnYyld9hE6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save as a model dedicated to inference\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRfuK8Y59hE6",
    "outputId": "106250fb-84e1-4ee8-bc8e-dcedb2bfd31c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/kf/9vc6x6n97q942grwf1zf0trw0000gn/T/tmp03uw5dkx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/kf/9vc6x6n97q942grwf1zf0trw0000gn/T/tmp03uw5dkx/assets\n",
      "2023-10-19 12:45:48.320017: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-10-19 12:45:48.320044: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-10-19 12:45:48.322744: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/kf/9vc6x6n97q942grwf1zf0trw0000gn/T/tmp03uw5dkx\n",
      "2023-10-19 12:45:48.325877: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-10-19 12:45:48.325902: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/kf/9vc6x6n97q942grwf1zf0trw0000gn/T/tmp03uw5dkx\n",
      "2023-10-19 12:45:48.331395: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
      "2023-10-19 12:45:48.333589: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-10-19 12:45:48.394377: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/kf/9vc6x6n97q942grwf1zf0trw0000gn/T/tmp03uw5dkx\n",
      "2023-10-19 12:45:48.412862: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 90130 microseconds.\n",
      "2023-10-19 12:45:48.442977: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8032"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform model (quantization)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHBPBXdx9hE6"
   },
   "source": [
    "## Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "mGAzLocO9hE7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "oQuDK8YS9hE7"
   },
   "outputs": [],
   "source": [
    "# Get I / O tensor\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "2_ixAf_l9hE7"
   },
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4FoAnuc9hE7",
    "outputId": "330d050b-a3fb-41ce-fa07-dc7a48d715e7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 607 s, sys: 343 s, total: 950 s\n",
      "Wall time: 718 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inference implementation\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vONjp19J9hE8",
    "outputId": "9338c9f1-499b-4e10-844d-950075e98a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5059413e-07 1.9959598e-04 2.4500233e-15 3.1080654e-16 2.5947408e-13\n",
      " 2.1029174e-07 7.6230382e-24 9.9980003e-01 1.6501217e-15]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GCHB0ELGs60"
   },
   "source": [
    "## Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2jM8I3jGdF6",
    "outputId": "bd2c08cc-d57c-4589-e4fa-f80389176b96"
   },
   "outputs": [],
   "source": [
    "!zip -r model.zip keypoint_classifier  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEqyprC6cMVF"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrjjSqlLcQ4O"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YO6VffaRcY3R"
   },
   "outputs": [],
   "source": [
    "# Init parameters to tune\n",
    "HP_NUM_UNITS_1 = hp.HParam('num_units_1', hp.Discrete([16, 32, 64]))\n",
    "HP_NUM_UNITS_2 = hp.HParam('num_units_2', hp.Discrete([8, 16, 32]))\n",
    "HP_NUM_UNITS_3 = hp.HParam('num_units_3', hp.Discrete([8, 16, 32]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMysvzFxctmG"
   },
   "outputs": [],
   "source": [
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS_1,HP_NUM_UNITS_2,HP_NUM_UNITS_3, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSDYqpKZgOBw"
   },
   "outputs": [],
   "source": [
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False, save_best_only=True)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ssEmXpJcxSp"
   },
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "\n",
    "  model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS_1], activation='relu'),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS_2], activation='relu'),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS_3], activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "  \n",
    "  model.compile(\n",
    "    optimizer=hparams[HP_OPTIMIZER],\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "  \n",
    "  cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False, save_best_only=True)\n",
    "\n",
    "  model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[\n",
    "               cp_callback,\n",
    "               es_callback,\n",
    "               ]\n",
    "  ) \n",
    "\n",
    "  # Load model with best accuracy\n",
    "  model = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "  _, accuracy = model.evaluate(X_test, y_test)\n",
    "  return accuracy\n",
    "\n",
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pO9W84DdHVL"
   },
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units_1 in HP_NUM_UNITS_1.domain.values:\n",
    "  for num_units_2 in HP_NUM_UNITS_2.domain.values:\n",
    "    for num_units_3 in HP_NUM_UNITS_3.domain.values:\n",
    "      for dropout_rate in np.arange(HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value, 0.1):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "          hparams = {\n",
    "              HP_NUM_UNITS_1: num_units_1,\n",
    "              HP_NUM_UNITS_2: num_units_2,\n",
    "              HP_NUM_UNITS_3: num_units_3,\n",
    "              HP_DROPOUT: dropout_rate,\n",
    "              HP_OPTIMIZER: optimizer,\n",
    "          }\n",
    "          run_name = \"run-%d\" % session_num\n",
    "          print('--- Starting trial: %s' % run_name)\n",
    "          print({h.name: hparams[h] for h in hparams})\n",
    "          run('logs/hparam_tuning/' + run_name, hparams)\n",
    "          session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21knbMYldaUn"
   },
   "outputs": [],
   "source": [
    "# !ATTENTION! Works only in Colab\n",
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6_UH6jttBsD"
   },
   "outputs": [],
   "source": [
    "!rm -rf logs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Keypoint_model_training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
